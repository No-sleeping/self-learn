## vxlan

<br/>

## overlay/underlay

<br/>

## 如何流量分析

https://blog.csdn.net/Dragon11123123/article/details/114857008

### 流量分类规则：

#### 二层：

- ·目的MAC地址
- ·源MAC地址
- ·VLAN报文外层Tag的ID信息
- ·VLAN报文外层Tāg的802.1p优先级
- ·VLAN报文内层Tag的ID信息
- ·VLAN报文内层Tag的802.1p优先级
- ·基于二层封装的协议字段
- MPLS报文的EXP优先级(AR1200&AR2200&AR3200&AR3600)
- ·FR报文中的DE标志位
- ·FR报文中的DLCI信息
- ·ATM报文中的PVC信息
- ·ACL4000~4999匹配的字段

#### 三层：

- IP报文的DSCP优先级
- IP报文的IP优先级
- IP协议类型(IPv4协议或IPv6协议)
- RTP端口号
- TCP报文的TCP-Flag标志
- IPv4报文长度
- IPSec策略的QoS group
- ACL2000~3999匹配的字段
- ACL62000~3999匹配的字段

#### 其他：

- 入接口
- 出接口
- SAC
- 用户组

<br/>

## 301/302 重定向 明细

### HTTP状态码302的跳转逻辑

302状态码表示重定向，浏览器在拿到服务器返回的这个状态码后会自动跳转到一个新的URL地址，这个地址可以从响应的Location首部中获取（用户看到的效果就是他输入的地址A瞬间变成了另一个地址B。

### 302与301的区别和使用场景

301的定义：301 Moved Permanently 被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个URI之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的。

302的定义：302 Found 请求的资源现在临时从不同的URI响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。

### 服务器端跳转和客户端跳转的区别

服务器端跳转就是指地址栏内容不变（客户端浏览器的地址栏不会显示目标地址的URL），客户端请求到达以后，服务器发现当前资源给不出回应，在服务器内部请求另一个资源的跳转。所以跳转与否客户端不知道，属于一次请求。

客户端跳转是指地址栏内容发生改变，客户端再根据服务器端给的响应中的URL再向服务器发送请求，所以是两次请求。客户端请求到达服务端，服务端返回一个 “去访问其他链接” 的回应。

<br/>

## HTTP 2.0

https://xiaolincoding.com/network/2_http/http2.html

第一点，对于常见的** HTTP 头部**通过静态表和 Huffman 编码的方式，将体积**压缩**了近一半，而且针对后续的请求头部，还可以建立动态表，将体积压缩近 90%，大大提高了编码效率，同时节约了带宽资源。不过，动态表并非可以无限增大， 因为动态表是会占用内存的，动态表越大，内存也越大，容易影响服务器总体的并发能力，因此服务器需要限制 HTTP/2 连接时长或者请求次数。

第二点，**HTTP/2 实现了 Stream 并发**，多个 Stream 只需复用 1 个 TCP 连接，节约了 TCP 和 TLS 握手时间，以及减少了 TCP 慢启动阶段对流量的影响。不同的 Stream ID 才可以并发，即时乱序发送帧也没问题，但是同一个 Stream 里的帧必须严格有序。

第三点，**服务器支持主动推送资源**，大大提升了消息的传输性能，服务器推送资源时，会先发送 PUSH_PROMISE 帧，告诉客户端接下来在哪个 Stream 发送资源，然后用偶数号 Stream 发送资源给客户端。

## TIME_WAIT

https://xiaolincoding.com/network/3_tcp/tcp_tw_reuse_close.html#%E4%B8%BA%E4%BB%80%E4%B9%88-tcp-tw-reuse-%E9%BB%98%E8%AE%A4%E6%98%AF%E5%85%B3%E9%97%AD%E7%9A%84

<br/>

## tcp_tw_reuse 何时开启

### 对于客户端：

1. 作为客户端因为有端口65535问题，TIME_OUT过多直接影响处理能力，打开tw_reuse 即可解决，不建议同时打开tw_recycle，帮助不大；
2. tw_reuse 帮助客户端1s完成连接回收，基本可实现单机6w/s短连接请求，需要再高就增加IP数量；
3. 如果内网压测场景，且客户端不需要接收连接，同时 tw_recycle 会有一点点好处；
4. 业务上也可以设计由服务端主动关闭连接。

### 对于服务端：

1. 打开tw_reuse无效
2. 线上环境 tw_recycle 不建议打开
3. 服务器TIME_WAIT 高怎么办。   不像客户端有端口限制，处理大量TIME_WAIT Linux已经优化很好了，每个处于TIME_WAIT 状态下连接内存消耗很少，而且也能通过tcp_max_tw_buckets = 262144 配置最大上限，现代机器一般也不缺这点内存。

<br/>

## 如何判断长短链接

长连接与短连接的概念是针对TCP连接的。TCP连接是一个双向通道，可以保持一段时间不关闭。

长连接是指在完成链路连接建立后，在链路空闲时并不结束这条链路，而是一直维持这条链路的连接，因此安全性较差。

短连接是每次通信结束后，连接中断，下次通信时重新建立连接。

长连接多应用于保持通信的场景，例如：消息推送、链路复用等。

短连接应用于HTTP技术，HTTP在向服务器交互信息时在一段时间内也会保持长连接。

长连接实现原理：长连接的维持，是要客户端程序定时向服务端程序发送一个维持连接包。如果长时间未发送维持连接包，服务端程序将断开连接。

HTTP1.1开始默认保持长连接，HTTP1.0是短连接。

在数据库的连接中使用的是长连接，如果用短连接频繁的通信会造成socket错误，频繁的socket创建也是对资源的浪费。

dubbo中使用RPC通信协议，是长连接，每个消费者和生产者之间建立一个TCO连接，调用一次接口后该连接还存在。

springcloud中使用RESTful http访问，是短连接

<br/>

## DNS解析过程

https://xiaolincoding.com/network/1_base/what_happen_url.html#%E5%AD%A4%E5%8D%95%E5%B0%8F%E5%BC%9F-http

---

## 用户使用 app 一个功能时，rt上涨，如何排查

## 评论的用例设计

 ---

## 两个有序数组，求其交集。
